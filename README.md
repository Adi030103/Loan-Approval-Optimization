# ğŸ’° Lending Club Default Prediction & Loan Approval Optimization
**Course Project: Predictive Modeling + Offline Reinforcement Learning**

---

## ğŸ§© Project Overview

This project builds two complementary AI systems for credit risk management using **Lending Clubâ€™s public loan dataset** (2007â€“2018):

1. **Deep Learning Classifier (Supervised)**
   - Predicts the probability of **loan default** from borrower features.
   - Evaluated using **AUC** and **F1-score**.

2. **Offline Reinforcement Learning Agent (Contextual Bandit)**
   - Learns a **loan approval policy** that maximizes **expected profit** directly.
   - Evaluated using **Estimated Policy Value (EPV)** â€” mean expected reward per applicant.

---

## âš™ï¸ Environment Setup

### 1. Clone / Download
```bash
git clone https://github.com/yourusername/lendingclub-rl.git
cd lendingclub-rl
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Verify installation
```python
import torch, xgboost, sklearn, pandas
```

âœ… If no errors appear, setup is complete.

---

## ğŸ“¦ Dataset

We used the official **Lending Club Accepted Loans** dataset:
```
accepted_2007_to_2018Q4.csv.gz
```

- Total records: ~2.26M loans
- Target column: `loan_status`
- Binary mapping:
  - `Fully Paid` â†’ 0
  - `Charged Off / Default` â†’ 1

---

## ğŸ§  Model 1 â€” Predictive Deep Learning Model

### **Goal:** Predict risk of default from applicant features.

**Pipeline:**
1. Cleaned missing values, parsed dates, converted percentage fields.
2. Engineered features:
   - `int_rate_num`, `revol_util_num`, `term_months`, `emp_len_yrs`, `credit_hist_mths`
3. Selected **leakage-free** features (only data known at decision time).
4. Trained **PyTorch MLP** (3 hidden layers, ReLU + Dropout).

**Results:**
| Metric | Value |
|:-------|:------|
| AUC | 0.708 |
| F1 (t=0.50) | 0.37 |

**Interpretation:**
- Model ranks borrowers by risk ~71% accurately.
- Balanced precisionâ€“recall for early-stage screening.

---

## ğŸ¤– Model 2 â€” Offline Reinforcement Learning Agent

### **Goal:** Learn a direct approve/deny policy to maximize profit.

| Component | Definition |
|:-----------|:------------|
| **State (s)** | Applicant features (88-dim vector) |
| **Action (a)** | {0: Deny, 1: Approve} |
| **Reward (r)** | `+ loan_amnt * int_rate` if paid; `- loan_amnt` if default; `0` if denied |

**Algorithm:**
- Trained **Direct Method (XGBoost regressor)** to predict expected reward.
- Policy rule: approve if predicted reward > 0.

**Results:**

| Policy | EPV (mean reward/applicant) | Approval Rate |
|:-------|------------------------------|----------------|
| DL @ 0.50 | 1,536.6 | 57.3% |
| DL @ 0.95 (profit-optimal) | 3,553.4 | 100% |
| RL (XGB-DM) | **3,494.7** | 96.9% |

---

## ğŸ“Š Key Graphs

### **1ï¸âƒ£ Estimated Policy Value by Policy**
![EPV Chart](artifacts/epv_chart.png)

### **2ï¸âƒ£ Approval Rate by Policy**
![Approval Rate](artifacts/approval_chart.png)

### **3ï¸âƒ£ Threshold Sweep**
![Threshold Sweep](artifacts/threshold_sweep.png)

---

## ğŸ§® Insights

- **DL model:** strong ranking, moderate classification.
- **RL policy:** directly profit-optimized, higher EPV.
- **High thresholds (â‰ˆ0.9â€“0.95)** balance risk vs reward.
- **Disagreements:** RL approves some high-risk/high-return loans DL rejects.

---

## ğŸš€ Future Work

- Add constraints (e.g., max default rate).
- Add fees, recoveries, prepayment effects in reward.
- Try **CQL/IQL** and **Doubly Robust** offline RL.
- Add interpretability and fairness modules.

---

## ğŸ“ Folder Structure

```
â”œâ”€â”€ artifacts/                # Models, outputs, charts
â”œâ”€â”€ data/                     # Lending Club dataset
â”œâ”€â”€ notebooks/                # Jupyter workflow
â”œâ”€â”€ src/                      # Code scripts
â”‚   â”œâ”€â”€ preprocess.py
â”‚   â”œâ”€â”€ train_mlp.py
â”‚   â”œâ”€â”€ train_rl.py
â”‚   â””â”€â”€ evaluate.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ‘¤ Author

**Avinash Pratap Singh**  
B.Tech CSE â€” Thapar Institute of Engineering & Technology  
ğŸ“§ avinash0308@example.com | ğŸŒ [LinkedIn](https://linkedin.com/in/avinash0308)

---
